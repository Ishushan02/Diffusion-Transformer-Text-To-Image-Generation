{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d5e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from diffusers import AutoencoderDC\n",
    "from diffusers import DDPMScheduler, DDIMScheduler\n",
    "from CombinationFunctions import PatchEmbedding\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a3ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 8, 8]), torch.Size([1, 3, 512, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedDimension, latentSize, latentChannels, patchSize, totalTimestamps=1000, beta_schedule = \"squaredcos_cap_v2\", modelName=\"mit-han-lab/dc-ae-f64c128-in-1.0-diffusers\"):\n",
    "        super().__init__()\n",
    "        self.dc_ae = AutoencoderDC.from_pretrained(modelName, torch_dtype=torch.float32)\n",
    "        self.noiseScheduler = DDPMScheduler(num_train_timesteps=totalTimestamps, beta_schedule=beta_schedule)\n",
    "        self.patchEmbedding = PatchEmbedding(imageSize = latentSize, patchSize = patchSize, inChannels = latentChannels, embedDimension = embedDimension)\n",
    "\n",
    "\n",
    "    def forward(self, x, timestep, noisyImage):\n",
    "        predictedNoise = self.patchEmbedding.unPatchify(x)\n",
    "\n",
    "        alphaT = self.noiseScheduler.alphas_cumprod[timestep].view(1, 1, 1, 1)\n",
    "        originallatents = (noisyImage - torch.sqrt(1 - alphaT) * predictedNoise) / torch.sqrt(alphaT)\n",
    "        originalImage = self.dc_ae.decode(originallatents).sample\n",
    "        originalImage = originalImage * 0.5 + 0.5\n",
    "\n",
    "        return predictedNoise, originalImage\n",
    "        \n",
    "\n",
    "dec = Decoder(embedDimension=784, latentSize=8, latentChannels=128, patchSize=2)\n",
    "noisyImage = torch.randn(1, 128, 8, 8)\n",
    "\n",
    "latents = torch.randn(1, 16, 784)\n",
    "predictedNoise, originalImage = dec(latents, 10, noisyImage)\n",
    "predictedNoise.shape, originalImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dda0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
