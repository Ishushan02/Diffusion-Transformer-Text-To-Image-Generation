{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c110014",
   "metadata": {},
   "source": [
    "Patchification Block, \n",
    "basically taking an image and splitting it down in to patches of images and then send it to input layer\n",
    "after flattening it.\n",
    "\n",
    "- Here in case of DiT, the patchification method is done on Noised Latent Images\n",
    "- Latents mean the image output adter passing it through Variation Encoder after which noise is added to it\n",
    "- So generally it will be a Layer of Patchifies latents + Positional Encodings which is responsible for \n",
    "keeping the information of positions of patches.\n",
    "- Our initial image is of size 256 * 256 which is converted to 32 * 32 after VAE \n",
    "- Now we have 2 options of creating patch size of 2 * 2 and 4 * 4 (let's keep it variable based on training Compute is left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d0d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 768]), torch.Size([1, 128, 8, 8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, imageSize, patchSize, inChannels, embedDimension):\n",
    "        super().__init__()\n",
    "        self.patchSize = patchSize\n",
    "        self.inChannels = inChannels\n",
    "        self.embedDimension = embedDimension\n",
    "        self.imageSize = imageSize\n",
    "\n",
    "        self.patches = imageSize//patchSize * imageSize//patchSize\n",
    "\n",
    "        self.encode = nn.Conv2d(in_channels = inChannels, out_channels = embedDimension, kernel_size = patchSize, stride = patchSize, bias = True)\n",
    "        self.decode = nn.ConvTranspose2d(in_channels=embedDimension, out_channels=inChannels, kernel_size=patchSize, stride=patchSize, bias=True)\n",
    "        self.positionalEmbedding = nn.Parameter(torch.zeros(1, self.patches, embedDimension))\n",
    "        nn.init.trunc_normal_(self.positionalEmbedding, std=0.02)\n",
    "\n",
    "    def unPatchify(self, x):\n",
    "        batchSize, NPatches, EmbedDim = x.shape\n",
    "        patchPerDim = self.imageSize // self.patchSize\n",
    "        x = x.transpose(1, 2).reshape(batchSize, EmbedDim, patchPerDim, patchPerDim)\n",
    "        out = self.decode(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, latentImage):\n",
    "\n",
    "        allPatch = self.encode(latentImage)\n",
    "        # print(allPatch.shape)\n",
    "        flattened = allPatch.flatten(2).transpose(1, 2)\n",
    "        # print(flattened.shape, self.positionalEmbedding.shape)\n",
    "        out = flattened + self.positionalEmbedding\n",
    "        return out\n",
    "\n",
    "latent = torch.randn(128, 8, 8).unsqueeze(0)\n",
    "pEmbed = PatchEmbedding(imageSize = 8, patchSize = 2, inChannels = 128, embedDimension = 768)\n",
    "out = pEmbed(latent)\n",
    "unpatched = pEmbed.unPatchify(out)\n",
    "out.shape, unpatched.shape\n",
    "# (batchSize, totalPatches, embeddinDimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5a838a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.transpose(1, 2).reshape(1, 768, 8, 8)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d7f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
